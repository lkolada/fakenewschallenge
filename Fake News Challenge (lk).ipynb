{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing general libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import time\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "# Importing libraries for data processing\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Importing libraries for modeling\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data is splited already on train / test sets\n",
    "train_heads = pd.read_csv('C:\\\\Users\\\\Lukasz1\\\\Desktop\\\\dane\\\\train_stances.csv')\n",
    "train_bodies = pd.read_csv('C:\\\\Users\\\\Lukasz1\\\\Desktop\\\\dane\\\\train_bodies.csv')\n",
    "test_heads = pd.read_csv('C:\\\\Users\\\\Lukasz1\\\\Desktop\\\\dane\\\\competition_test_stances.csv')\n",
    "test_bodies = pd.read_csv('C:\\\\Users\\\\Lukasz1\\\\Desktop\\\\dane\\\\competition_test_bodies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Investigating train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated\n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree\n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated\n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated\n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_heads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49972 entries, 0 to 49971\n",
      "Data columns (total 3 columns):\n",
      "Headline    49972 non-null object\n",
      "Body ID     49972 non-null int64\n",
      "Stance      49972 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_heads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                             49972\n",
       "unique                                             1648\n",
       "top       ISIL Beheads American Photojournalist in Iraq\n",
       "freq                                                127\n",
       "Name: Headline, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_heads.Headline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_heads['Body ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1921    187\n",
       "1948    175\n",
       "40      172\n",
       "524     171\n",
       "1549    166\n",
       "304     154\n",
       "1385    151\n",
       "125     145\n",
       "2367    143\n",
       "220     141\n",
       "1438    141\n",
       "195     140\n",
       "2296    136\n",
       "35      131\n",
       "1786    131\n",
       "1883    131\n",
       "2520    127\n",
       "1034    127\n",
       "2252    126\n",
       "1574    125\n",
       "2307    125\n",
       "527     125\n",
       "2175    124\n",
       "1627    123\n",
       "2404    123\n",
       "1289    122\n",
       "2115    121\n",
       "2096    120\n",
       "1040    118\n",
       "1893    117\n",
       "       ... \n",
       "907       1\n",
       "370       1\n",
       "210       1\n",
       "146       1\n",
       "114       1\n",
       "1542      1\n",
       "63        1\n",
       "76        1\n",
       "390       1\n",
       "515       1\n",
       "193       1\n",
       "464       1\n",
       "355       1\n",
       "323       1\n",
       "624       1\n",
       "282       1\n",
       "18        1\n",
       "797       1\n",
       "701       1\n",
       "362       1\n",
       "2311      1\n",
       "6         1\n",
       "915       1\n",
       "70        1\n",
       "151       1\n",
       "376       1\n",
       "140       1\n",
       "307       1\n",
       "1066      1\n",
       "59        1\n",
       "Name: Body ID, Length: 1683, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_heads['Body ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        0  A small meteorite crashed into a wooded area i...\n",
       "1        4  Last week we hinted at what was to come as Ebo...\n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...\n",
       "3        6  Posting photos of a gun-toting child online, I...\n",
       "4        7  At least 25 suspected Boko Haram insurgents we..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1683 entries, 0 to 1682\n",
      "Data columns (total 2 columns):\n",
      "Body ID        1683 non-null int64\n",
      "articleBody    1683 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 26.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_bodies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                  1683\n",
       "unique                                                 1669\n",
       "top       When Apple introduced its Apple Watch in Septe...\n",
       "freq                                                      2\n",
       "Name: articleBody, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bodies.articleBody.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_bodies['Body ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_bodies['Body ID']) == set(train_heads['Body ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ferguson riots: Pregnant woman loses eye after...</td>\n",
       "      <td>2008</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crazy Conservatives Are Sure a Gitmo Detainee ...</td>\n",
       "      <td>1550</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Russian Guy Says His Justin Bieber Ringtone ...</td>\n",
       "      <td>2</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zombie Cat: Buried Kitty Believed Dead, Meows ...</td>\n",
       "      <td>1793</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina's President Adopts Boy to End Werewo...</td>\n",
       "      <td>37</td>\n",
       "      <td>unrelated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance\n",
       "0  Ferguson riots: Pregnant woman loses eye after...     2008  unrelated\n",
       "1  Crazy Conservatives Are Sure a Gitmo Detainee ...     1550  unrelated\n",
       "2  A Russian Guy Says His Justin Bieber Ringtone ...        2  unrelated\n",
       "3  Zombie Cat: Buried Kitty Believed Dead, Meows ...     1793  unrelated\n",
       "4  Argentina's President Adopts Boy to End Werewo...       37  unrelated"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_heads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25413 entries, 0 to 25412\n",
      "Data columns (total 3 columns):\n",
      "Headline    25413 non-null object\n",
      "Body ID     25413 non-null int64\n",
      "Stance      25413 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 595.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test_heads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                           25413\n",
       "unique                                            894\n",
       "top       Source: Joan Rivers' doc did biopsy, selfie\n",
       "freq                                              160\n",
       "Name: Headline, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_heads.Headline.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test_heads['Body ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1373    161\n",
       "2383    136\n",
       "338     132\n",
       "1639    123\n",
       "1394    122\n",
       "1765    119\n",
       "2512    115\n",
       "1454    110\n",
       "2427    108\n",
       "1275    103\n",
       "1770    103\n",
       "3       103\n",
       "274     103\n",
       "2233    102\n",
       "535     101\n",
       "2320    101\n",
       "1272     98\n",
       "2279     97\n",
       "1431     97\n",
       "1754     97\n",
       "1386     94\n",
       "934      93\n",
       "2289     92\n",
       "1326     91\n",
       "1102     91\n",
       "2491     90\n",
       "2040     89\n",
       "758      87\n",
       "1886     87\n",
       "1851     87\n",
       "       ... \n",
       "590       1\n",
       "66        1\n",
       "857       1\n",
       "310       1\n",
       "770       1\n",
       "278       1\n",
       "102       1\n",
       "642       1\n",
       "64        1\n",
       "270       1\n",
       "1230      1\n",
       "237       1\n",
       "496       1\n",
       "131       1\n",
       "184       1\n",
       "49        1\n",
       "165       1\n",
       "287       1\n",
       "543       1\n",
       "191       1\n",
       "380       1\n",
       "309       1\n",
       "127       1\n",
       "436       1\n",
       "421       1\n",
       "31        1\n",
       "849       1\n",
       "71        1\n",
       "106       1\n",
       "306       1\n",
       "Name: Body ID, Length: 904, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_heads['Body ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A bereaved Afghan mother took revenge on the T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CNBC is reporting Tesla has chosen Nevada as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>A 4-inch version of the iPhone 6 is said to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>GR editor’s Note\\n\\nThere are no reports in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody\n",
       "0        1  Al-Sisi has denied Israeli reports stating tha...\n",
       "1        2  A bereaved Afghan mother took revenge on the T...\n",
       "2        3  CNBC is reporting Tesla has chosen Nevada as t...\n",
       "3       12  A 4-inch version of the iPhone 6 is said to be...\n",
       "4       19  GR editor’s Note\\n\\nThere are no reports in th..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bodies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 904 entries, 0 to 903\n",
      "Data columns (total 2 columns):\n",
      "Body ID        904 non-null int64\n",
      "articleBody    904 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test_bodies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                   904\n",
       "unique                                                  900\n",
       "top       A wicked aunt cut her three-year-old nephew’s ...\n",
       "freq                                                      2\n",
       "Name: articleBody, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bodies.articleBody.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test_bodies['Body ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_heads['Body ID']) == set(test_bodies['Body ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_of_classes(dataframe, column='Stance'):\n",
    "    no_stances = Counter(dataframe[column])\n",
    "    stances_data = pd.DataFrame.from_dict(no_stances, orient='index')\n",
    "    stances_data.columns = ['count']\n",
    "    total_no_counts = 0\n",
    "    for index, row in stances_data.iterrows():\n",
    "        total_no_counts += row['count']\n",
    "    stances_data['%counts'] = round(stances_data['count']/total_no_counts*100)\n",
    "    stances_data['count'].plot(kind='bar')\n",
    "    print(stances_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           count  %counts\n",
      "unrelated  36545     73.0\n",
      "agree       3678      7.0\n",
      "disagree     840      2.0\n",
      "discuss     8909     18.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEiCAYAAAASzx4jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ55KbPHtXEEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x227cec3d588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_of_classes(train_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           count  %counts\n",
      "unrelated  18349     72.0\n",
      "agree       1903      7.0\n",
      "discuss     4464     18.0\n",
      "disagree     697      3.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEiCAYAAAASzx4jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x227ced21940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number_of_classes(test_heads)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "There are more headlines than article bodies.\n",
    "Therefore, one article is used for multiple headlines.\n",
    "There is much more unrelated pairs (72-73%) than any other class.\n",
    "On the other hand, class disagree is underrepresented (2-3%).\n",
    "\n",
    "To dos:\n",
    "1. Preprocessing the data - removing punctation, leaving only words, lowering words, removing stop words - that step for both train and test sets.\n",
    "2. Getting unique headlines and article bodies. Model will be based on most popular words: hence, if articles repeats themselves we must select only those which are unique. This step is necessary only for train set.\n",
    "3. Getting the list of the most common words - that's on what the model will be built. This step is necessary only for train set.\n",
    "4 Transforming headlines and article bodies into vectors that later will be used in the classification models. Each row (observation or headline + arcticle body pair) will be transformed into matrix that is built on:\n",
    "- term frequency (n most popular words) of Headlines \n",
    "- term frequency (n most popular words) of Article Bodies\n",
    "- TFIDF cosine similarity of TFIDF of Headlines and TFIDF of Article Bodies.\n",
    "All these elements will be merge  The result of the transformation will be matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Initialise fuctions for data processing (explained above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading English stopwords\n",
    "f = open('C:\\\\Users\\\\Lukasz1\\\\Desktop\\\\dane\\\\stopwords-en.txt', 'r')\n",
    "english_stop_words = f.read().split('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising fuction for text processing (leaving only alphabetic characters, lowercase, removing stopwords)\n",
    "def preprocessing(data, column):\n",
    "    table = []\n",
    "    table = [re.sub(\"[^a-zA-Z]\", \" \",str(a)) for a in data[column]]\n",
    "    table = [word_tokenize(a) for a in table]\n",
    "    table = [[w.lower() for w in a] for a in table]\n",
    "    table = [[w for w in a if w not in english_stop_words] for a in table]\n",
    "    table = [' '.join(x) for x in table]\n",
    "    data[column] = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising fuction for merging Headline and Article Body datasets\n",
    "def merge_data(data1, data2, left_on=['Body ID'], right_on=['Body ID']):\n",
    "    full_data = pd.merge(data1, data2,  how='inner', left_on=['Body ID'], right_on=['Body ID'])\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising fuction for selecting unique headlines and article bodies\n",
    "def get_unique_strings(dataframe, colname1='Headline', colname2='articleBody'):\n",
    "    unique_strings = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if row[colname1] not in unique_strings:\n",
    "            unique_strings.append(row[colname1])\n",
    "        if row[colname2] not in unique_strings:\n",
    "            unique_strings.append(row[colname2])\n",
    "    return unique_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counting the most frequent words. NOTE - changed aproach no longer in use\n",
    "def most_common_words(list_of_text, n):\n",
    "    tokens = []\n",
    "    for i in list_of_text:\n",
    "        tokens.extend(word_tokenize(i))\n",
    "    freq = FreqDist(tokens)\n",
    "    number_of_words = len(freq)\n",
    "    words = freq.most_common(n)\n",
    "    words_list = [i[0] for i in words]\n",
    "    return words_list, number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising fuction for changing text to vectors\n",
    "def new_process_data(unique_strings, n_words, dataframe):\n",
    "    tfvectorizer = TfidfVectorizer(max_features=n_words, use_idf=False).fit(unique_strings)\n",
    "    tfidfvectorizer = TfidfVectorizer(max_features=n_words, use_idf=True).fit(unique_strings)\n",
    "    data = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        head = row['Headline']\n",
    "        body = row['articleBody']\n",
    "        head_tf = tfvectorizer.transform([head]).toarray().reshape(1, -1)\n",
    "        body_tf = tfvectorizer.transform([body]).toarray().reshape(1, -1)\n",
    "        head_tfidf = tfidfvectorizer.transform([head]).toarray()\n",
    "        body_tfidf = tfidfvectorizer.transform([body]).toarray()\n",
    "        tfidf_cos = cosine_similarity(head_tfidf, body_tfidf).reshape(1, -1)\n",
    "        feat_vec = np.squeeze(np.c_[head_tf, body_tf, tfidf_cos])\n",
    "        data.append(feat_vec)\n",
    "    data = np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running functions in order to process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessing(train_heads, 'Headline')\n",
    "preprocessing(train_bodies, 'articleBody')\n",
    "preprocessing(test_heads, 'Headline')\n",
    "preprocessing(test_bodies, 'articleBody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = merge_data(train_heads, train_bodies)\n",
    "test = merge_data(test_heads, test_bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_trains = get_unique_strings(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_most_common_words, total_number_of_words = most_common_words(unique_trains, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21634"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = new_process_data(unique_trains, 2000, train)\n",
    "X_test = new_process_data(unique_trains, 2000, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 4001)\n",
      "(25413, 4001)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train.Stance.map({'unrelated': 0, 'disagree': 1, 'discuss' : 2, 'agree' : 3})\n",
    "y_test = test.Stance.map({'unrelated': 0, 'disagree': 1, 'discuss' : 2, 'agree' : 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972,)\n",
      "(25413,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Initialising some models that support multiclass classification. Apart from accuracy score, F1 score for each class is calculated. Saving scores in lists, so later they can be easly compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_models = []\n",
    "F1_score_unrelated = []\n",
    "F1_score_disagree = []\n",
    "F1_score_discuss = []\n",
    "F1_score_agree = []\n",
    "F1_score_weighted_list = []\n",
    "accuracy_list = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 7.65 minutes\n",
      "Decision Tree\n",
      "F1 score, class Unrelated: 90.21% \n",
      "F1 score, class Disagree: 7.46% \n",
      "F1 score, class Discuss: 56.32% \n",
      "F1 score, class Agree: 35.85%\n",
      "F1 score weighted: 77.91%\n",
      "Accuracy: 77.74%\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "name = 'Decision Tree'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print(name)\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models.append(name)\n",
    "F1_score_unrelated.append(f1_scores[0]*100)\n",
    "F1_score_disagree.append(f1_scores[1]*100)\n",
    "F1_score_discuss.append(f1_scores[2]*100)\n",
    "F1_score_agree.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list.append(f1_score_weighted*100)\n",
    "accuracy_list.append(accuracy*100)\n",
    "times.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 3.27 minutes\n",
      "Logistic Regression\n",
      "F1 score, class Unrelated: 93.97% \n",
      "F1 score, class Disagree: 0.86% \n",
      "F1 score, class Discuss: 67.06% \n",
      "F1 score, class Agree: 44.77%\n",
      "F1 score weighted: 83.01%\n",
      "Accuracy: 84.96%\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='saga', multi_class='multinomial')\n",
    "name = 'Logistic Regression'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print(name)\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models.append(name)\n",
    "F1_score_unrelated.append(f1_scores[0]*100)\n",
    "F1_score_disagree.append(f1_scores[1]*100)\n",
    "F1_score_discuss.append(f1_scores[2]*100)\n",
    "F1_score_agree.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list.append(f1_score_weighted*100)\n",
    "accuracy_list.append(accuracy*100)\n",
    "times.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 0.56 minutes\n",
      "Random Forest\n",
      "F1 score, class Unrelated: 92.20% \n",
      "F1 score, class Disagree: 1.13% \n",
      "F1 score, class Discuss: 59.15% \n",
      "F1 score, class Agree: 34.63%\n",
      "F1 score weighted: 79.58%\n",
      "Accuracy: 81.47%\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "name = 'Random Forest'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print(name)\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models.append(name)\n",
    "F1_score_unrelated.append(f1_scores[0]*100)\n",
    "F1_score_disagree.append(f1_scores[1]*100)\n",
    "F1_score_discuss.append(f1_scores[2]*100)\n",
    "F1_score_agree.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list.append(f1_score_weighted*100)\n",
    "accuracy_list.append(accuracy*100)\n",
    "times.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 9.03 minutes\n",
      "QDA\n",
      "F1 score, class Unrelated: 4.75% \n",
      "F1 score, class Disagree: 4.86% \n",
      "F1 score, class Discuss: 24.44% \n",
      "F1 score, class Agree: 0.82%\n",
      "F1 score weighted: 7.91%\n",
      "Accuracy: 9.22%\n"
     ]
    }
   ],
   "source": [
    "model = QuadraticDiscriminantAnalysis()\n",
    "name = 'QDA'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print(name)\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models.append(name)\n",
    "F1_score_unrelated.append(f1_scores[0]*100)\n",
    "F1_score_disagree.append(f1_scores[1]*100)\n",
    "F1_score_discuss.append(f1_scores[2]*100)\n",
    "F1_score_agree.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list.append(f1_score_weighted*100)\n",
    "accuracy_list.append(accuracy*100)\n",
    "times.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 0.24 minutes\n",
      "Extra Tree\n",
      "F1 score, class Unrelated: 82.67% \n",
      "F1 score, class Disagree: 11.22% \n",
      "F1 score, class Discuss: 46.89% \n",
      "F1 score, class Agree: 26.98%\n",
      "F1 score weighted: 70.25%\n",
      "Accuracy: 68.01%\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreeClassifier()\n",
    "name = 'Extra Tree'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print(name)\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models.append(name)\n",
    "F1_score_unrelated.append(f1_scores[0]*100)\n",
    "F1_score_disagree.append(f1_scores[1]*100)\n",
    "F1_score_discuss.append(f1_scores[2]*100)\n",
    "F1_score_agree.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list.append(f1_score_weighted*100)\n",
    "accuracy_list.append(accuracy*100)\n",
    "times.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 1.24 minutes\n",
      "Linear SVC\n",
      "F1 score, class Unrelated: 92.19% \n",
      "F1 score, class Disagree: 4.99% \n",
      "F1 score, class Discuss: 61.41% \n",
      "F1 score, class Agree: 42.50%\n",
      "F1 score weighted: 80.67%\n",
      "Accuracy: 81.63%\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(multi_class='crammer_singer')\n",
    "name = 'Linear SVC'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print(name)\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models.append(name)\n",
    "F1_score_unrelated.append(f1_scores[0]*100)\n",
    "F1_score_disagree.append(f1_scores[1]*100)\n",
    "F1_score_discuss.append(f1_scores[2]*100)\n",
    "F1_score_agree.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list.append(f1_score_weighted*100)\n",
    "accuracy_list.append(accuracy*100)\n",
    "times.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 1.19 minutes\n",
      "Bernoulli NB\n",
      "F1 score, class Unrelated: 77.48% \n",
      "F1 score, class Disagree: 4.48% \n",
      "F1 score, class Discuss: 25.17% \n",
      "F1 score, class Agree: 33.38%\n",
      "F1 score weighted: 62.99%\n",
      "Accuracy: 61.96%\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "name = 'Bernoulli NB'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print(name)\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models.append(name)\n",
    "F1_score_unrelated.append(f1_scores[0]*100)\n",
    "F1_score_disagree.append(f1_scores[1]*100)\n",
    "F1_score_discuss.append(f1_scores[2]*100)\n",
    "F1_score_agree.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list.append(f1_score_weighted*100)\n",
    "accuracy_list.append(accuracy*100)\n",
    "times.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 1.69 minutes\n",
      "Gaussian NB\n",
      "F1 score, class Unrelated: 22.15% \n",
      "F1 score, class Disagree: 10.12% \n",
      "F1 score, class Discuss: 28.73% \n",
      "F1 score, class Agree: 14.93%\n",
      "F1 score weighted: 22.43%\n",
      "Accuracy: 21.26%\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "name = 'Gaussian NB'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print(name)\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models.append(name)\n",
    "F1_score_unrelated.append(f1_scores[0]*100)\n",
    "F1_score_disagree.append(f1_scores[1]*100)\n",
    "F1_score_discuss.append(f1_scores[2]*100)\n",
    "F1_score_agree.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list.append(f1_score_weighted*100)\n",
    "accuracy_list.append(accuracy*100)\n",
    "times.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_dict = {'model' : list_of_models, \n",
    "                'F1 score, class Unrelated' : F1_score_unrelated, \n",
    "                'F1 score, class Disagree' : F1_score_disagree, \n",
    "                'F1 score, class Discuss' : F1_score_discuss, \n",
    "                'F1 score, class Agree' : F1_score_agree, \n",
    "                'F1 score weighted' : F1_score_weighted_list,\n",
    "                'Accuracy' : accuracy_list, \n",
    "                'Time (in minutes)' : times}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(summary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score weighted</th>\n",
       "      <th>F1 score, class Agree</th>\n",
       "      <th>F1 score, class Disagree</th>\n",
       "      <th>F1 score, class Discuss</th>\n",
       "      <th>F1 score, class Unrelated</th>\n",
       "      <th>Time (in minutes)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.735805</td>\n",
       "      <td>77.914813</td>\n",
       "      <td>35.845214</td>\n",
       "      <td>7.462687</td>\n",
       "      <td>56.319608</td>\n",
       "      <td>90.207830</td>\n",
       "      <td>7.65</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.964388</td>\n",
       "      <td>83.007035</td>\n",
       "      <td>44.773414</td>\n",
       "      <td>0.855920</td>\n",
       "      <td>67.057170</td>\n",
       "      <td>93.973197</td>\n",
       "      <td>3.27</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.470114</td>\n",
       "      <td>79.583966</td>\n",
       "      <td>34.626690</td>\n",
       "      <td>1.126761</td>\n",
       "      <td>59.145775</td>\n",
       "      <td>92.199066</td>\n",
       "      <td>0.56</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.219691</td>\n",
       "      <td>7.914609</td>\n",
       "      <td>0.821777</td>\n",
       "      <td>4.864328</td>\n",
       "      <td>24.439746</td>\n",
       "      <td>4.745799</td>\n",
       "      <td>9.03</td>\n",
       "      <td>QDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.008500</td>\n",
       "      <td>70.252298</td>\n",
       "      <td>26.981092</td>\n",
       "      <td>11.220715</td>\n",
       "      <td>46.890232</td>\n",
       "      <td>82.665966</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Extra Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.627513</td>\n",
       "      <td>80.673364</td>\n",
       "      <td>42.504849</td>\n",
       "      <td>4.986877</td>\n",
       "      <td>61.409999</td>\n",
       "      <td>92.193329</td>\n",
       "      <td>1.24</td>\n",
       "      <td>Linear SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61.964349</td>\n",
       "      <td>62.987773</td>\n",
       "      <td>33.375675</td>\n",
       "      <td>4.481793</td>\n",
       "      <td>25.169246</td>\n",
       "      <td>77.481881</td>\n",
       "      <td>1.19</td>\n",
       "      <td>Bernoulli NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.256837</td>\n",
       "      <td>22.433639</td>\n",
       "      <td>14.930191</td>\n",
       "      <td>10.123796</td>\n",
       "      <td>28.734168</td>\n",
       "      <td>22.146619</td>\n",
       "      <td>1.69</td>\n",
       "      <td>Gaussian NB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  F1 score weighted  F1 score, class Agree  \\\n",
       "0  77.735805          77.914813              35.845214   \n",
       "1  84.964388          83.007035              44.773414   \n",
       "2  81.470114          79.583966              34.626690   \n",
       "3   9.219691           7.914609               0.821777   \n",
       "4  68.008500          70.252298              26.981092   \n",
       "5  81.627513          80.673364              42.504849   \n",
       "6  61.964349          62.987773              33.375675   \n",
       "7  21.256837          22.433639              14.930191   \n",
       "\n",
       "   F1 score, class Disagree  F1 score, class Discuss  \\\n",
       "0                  7.462687                56.319608   \n",
       "1                  0.855920                67.057170   \n",
       "2                  1.126761                59.145775   \n",
       "3                  4.864328                24.439746   \n",
       "4                 11.220715                46.890232   \n",
       "5                  4.986877                61.409999   \n",
       "6                  4.481793                25.169246   \n",
       "7                 10.123796                28.734168   \n",
       "\n",
       "   F1 score, class Unrelated  Time (in minutes)                model  \n",
       "0                  90.207830               7.65        Decision Tree  \n",
       "1                  93.973197               3.27  Logistic Regression  \n",
       "2                  92.199066               0.56        Random Forest  \n",
       "3                   4.745799               9.03                  QDA  \n",
       "4                  82.665966               0.24           Extra Tree  \n",
       "5                  92.193329               1.24           Linear SVC  \n",
       "6                  77.481881               1.19         Bernoulli NB  \n",
       "7                  22.146619               1.69          Gaussian NB  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For Voting Classifier I choose these models which have in general high accuracy, but also they have relatievly good F1 scores on other classes than Unrelated. Therefore I choose:\n",
    "- Linear SVC (42% on class Agree and 61% on Discuss)\n",
    "- Logistic Regression (45% on class Agree and 67% on Discuss)\n",
    "- Decision Tree and Extra Tree (on class Disagree respectively 7% and 11%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 10.29 minutes\n",
      "F1 score, class Unrelated: 93.84% \n",
      "F1 score, class Disagree: 0.85% \n",
      "F1 score, class Discuss: 66.48% \n",
      "F1 score, class Agree: 40.60%\n",
      "F1 score weighted: 82.50%\n",
      "Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "models = [LogisticRegression(solver='saga', multi_class='multinomial'), \n",
    "          LinearSVC(multi_class='crammer_singer'),\n",
    "          DecisionTreeClassifier(),\n",
    "          ExtraTreeClassifier()]\n",
    "\n",
    "model = VotingClassifier(estimators=list(zip([\"lr\",\"lsvc\",\"dtr\",'exc'],models)),voting=\"hard\")\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'Voting Classifier'\n",
    "list_of_models1.append(name)\n",
    "F1_score_unrelated1.append(f1_scores[0]*100)\n",
    "F1_score_disagree1.append(f1_scores[1]*100)\n",
    "F1_score_discuss1.append(f1_scores[2]*100)\n",
    "F1_score_agree1.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list1.append(f1_score_weighted*100)\n",
    "accuracy_list1.append(accuracy*100)\n",
    "times1.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
      "          n_jobs=1, penalty='l2', random_state=None, solver='saga',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of modeling: 170.44 minutes\n",
      "[mean: 0.90464, std: 0.00504, params: {'C': 0.5, 'penalty': 'l1'},\n",
      " mean: 0.90875, std: 0.00442, params: {'C': 0.5, 'penalty': 'l2'},\n",
      " mean: 0.90650, std: 0.00556, params: {'C': 1, 'penalty': 'l1'},\n",
      " mean: 0.91101, std: 0.00306, params: {'C': 1, 'penalty': 'l2'},\n",
      " mean: 0.90122, std: 0.00374, params: {'C': 3, 'penalty': 'l1'},\n",
      " mean: 0.90958, std: 0.00218, params: {'C': 3, 'penalty': 'l2'}]\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='crammer_singer', penalty='l2', random_state=None,\n",
      "     tol=0.0001, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of modeling: 23.41 minutes\n",
      "[mean: 0.90875, std: 0.00132, params: {'C': 0.5, 'penalty': 'l1'},\n",
      " mean: 0.90875, std: 0.00132, params: {'C': 0.5, 'penalty': 'l2'},\n",
      " mean: 0.90274, std: 0.00291, params: {'C': 1, 'penalty': 'l1'},\n",
      " mean: 0.90275, std: 0.00291, params: {'C': 1, 'penalty': 'l2'},\n",
      " mean: 0.89329, std: 0.00299, params: {'C': 3, 'penalty': 'l1'},\n",
      " mean: 0.89329, std: 0.00298, params: {'C': 3, 'penalty': 'l2'}]\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of modeling: 37.29 minutes\n",
      "[mean: 0.81279, std: 0.03098, params: {'criterion': 'gini', 'min_samples_leaf': 1},\n",
      " mean: 0.85847, std: 0.00316, params: {'criterion': 'gini', 'min_samples_leaf': 5},\n",
      " mean: 0.86988, std: 0.00820, params: {'criterion': 'gini', 'min_samples_leaf': 10},\n",
      " mean: 0.84214, std: 0.01889, params: {'criterion': 'entropy', 'min_samples_leaf': 1},\n",
      " mean: 0.86836, std: 0.00907, params: {'criterion': 'entropy', 'min_samples_leaf': 5},\n",
      " mean: 0.88120, std: 0.00341, params: {'criterion': 'entropy', 'min_samples_leaf': 10}]\n",
      "ExtraTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of modeling: 1.65 minutes\n",
      "[mean: 0.58741, std: 0.10348, params: {'criterion': 'gini', 'min_samples_leaf': 1},\n",
      " mean: 0.65221, std: 0.08477, params: {'criterion': 'gini', 'min_samples_leaf': 5},\n",
      " mean: 0.61535, std: 0.00977, params: {'criterion': 'gini', 'min_samples_leaf': 10},\n",
      " mean: 0.54742, std: 0.11087, params: {'criterion': 'entropy', 'min_samples_leaf': 1},\n",
      " mean: 0.63489, std: 0.11584, params: {'criterion': 'entropy', 'min_samples_leaf': 5},\n",
      " mean: 0.66042, std: 0.02245, params: {'criterion': 'entropy', 'min_samples_leaf': 10}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lukasz1\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "best_params = []\n",
    "\n",
    "models = [LogisticRegression(solver='saga', multi_class='multinomial'), \n",
    "          LinearSVC(multi_class='crammer_singer'),\n",
    "          DecisionTreeClassifier(),\n",
    "          ExtraTreeClassifier()]\n",
    "\n",
    "param_grids = [{\"penalty\":[\"l1\",\"l2\"], \"C\":[0.5,1,3]},\n",
    "               {\"penalty\":[\"l1\",\"l2\"], \"C\":[0.5,1,3]},\n",
    "               {\"criterion\": ['gini', 'entropy'], \"min_samples_leaf\": [1,5,10]},\n",
    "               {\"criterion\": ['gini', 'entropy'], \"min_samples_leaf\": [1,5,10]}]\n",
    "\n",
    "for model, grid in zip(models,param_grids):\n",
    "    start_time = time.time()\n",
    "    print(model)\n",
    "    cv = GridSearchCV(model,grid,scoring=\"f1_weighted\")\n",
    "    cv.fit(X_train,y_train)\n",
    "    time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "    print(\"Time of modeling: %s minutes\" % (time_of_model))\n",
    "    best_params.append(cv.best_params_)\n",
    "    pprint(cv.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_models1 = []\n",
    "F1_score_unrelated1 = []\n",
    "F1_score_disagree1 = []\n",
    "F1_score_discuss1 = []\n",
    "F1_score_agree1 = []\n",
    "F1_score_weighted_list1 = []\n",
    "accuracy_list1 = []\n",
    "times1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 0.3 minutes\n",
      "Linear SVC (optimised)\n",
      "F1 score, class Unrelated: 92.88% \n",
      "F1 score, class Disagree: 3.97% \n",
      "F1 score, class Discuss: 63.61% \n",
      "F1 score, class Agree: 44.27%\n",
      "F1 score weighted: 81.66%\n",
      "Accuracy: 82.96%\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(multi_class='crammer_singer', C=0.5)\n",
    "name = 'Linear SVC (optimised)'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print(name)\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models1.append(name)\n",
    "F1_score_unrelated1.append(f1_scores[0]*100)\n",
    "F1_score_disagree1.append(f1_scores[1]*100)\n",
    "F1_score_discuss1.append(f1_scores[2]*100)\n",
    "F1_score_agree1.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list1.append(f1_score_weighted*100)\n",
    "accuracy_list1.append(accuracy*100)\n",
    "times1.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 2.92 minutes\n",
      "Decision Tree (optimised)\n",
      "F1 score, class Unrelated: 94.16% \n",
      "F1 score, class Disagree: 12.32% \n",
      "F1 score, class Discuss: 61.80% \n",
      "F1 score, class Agree: 39.94%\n",
      "F1 score weighted: 82.17%\n",
      "Accuracy: 83.27%\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=10)\n",
    "name = 'Decision Tree (optimised)'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print(name)\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models1.append(name)\n",
    "F1_score_unrelated1.append(f1_scores[0]*100)\n",
    "F1_score_disagree1.append(f1_scores[1]*100)\n",
    "F1_score_discuss1.append(f1_scores[2]*100)\n",
    "F1_score_agree1.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list1.append(f1_score_weighted*100)\n",
    "accuracy_list1.append(accuracy*100)\n",
    "times1.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 0.1 minutes\n",
      "Extra Tree (optimised)\n",
      "F1 score, class Unrelated: 83.05% \n",
      "F1 score, class Disagree: 1.11% \n",
      "F1 score, class Discuss: 34.78% \n",
      "F1 score, class Agree: 26.50%\n",
      "F1 score weighted: 68.09%\n",
      "Accuracy: 69.10%\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreeClassifier(criterion='entropy', min_samples_leaf=10)\n",
    "name = 'Extra Tree (optimised)'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print(name)\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models1.append(name)\n",
    "F1_score_unrelated1.append(f1_scores[0]*100)\n",
    "F1_score_disagree1.append(f1_scores[1]*100)\n",
    "F1_score_discuss1.append(f1_scores[2]*100)\n",
    "F1_score_agree1.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list1.append(f1_score_weighted*100)\n",
    "accuracy_list1.append(accuracy*100)\n",
    "times1.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of fitting: 6.55 minutes\n",
      "F1 score, class Unrelated: 93.95% \n",
      "F1 score, class Disagree: 2.72% \n",
      "F1 score, class Discuss: 66.80% \n",
      "F1 score, class Agree: 43.39%\n",
      "F1 score weighted: 82.90%\n",
      "Accuracy: 84.93%\n"
     ]
    }
   ],
   "source": [
    "models = [LogisticRegression(solver='saga', multi_class='multinomial'), \n",
    "          LinearSVC(multi_class='crammer_singer', C=0.5),\n",
    "          DecisionTreeClassifier(criterion='entropy', min_samples_leaf=10),\n",
    "          ExtraTreeClassifier(criterion='entropy', min_samples_leaf=10)]\n",
    "\n",
    "model = VotingClassifier(estimators=list(zip([\"lr\",\"lsvc\",\"dtr\",'exc'],models)),voting=\"hard\")\n",
    "name = 'Voting Classifier (optimised)'\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "time_of_model = round((time.time() - start_time) / 60, 2)\n",
    "print(\"Time of fitting: %s minutes\" % (time_of_model))\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "f1_scores = metrics.f1_score(y_test, y_pred, labels=labels, average=None)\n",
    "f1_score_weighted = metrics.f1_score(y_test, y_pred, labels=labels, average='weighted')\n",
    "print('F1 score, class Unrelated: %.2f%%' % (f1_scores[0]*100),'\\n'\n",
    "     'F1 score, class Disagree: %.2f%%' % (f1_scores[1]*100),'\\n'\n",
    "     'F1 score, class Discuss: %.2f%%' % (f1_scores[2]*100),'\\n'\n",
    "     'F1 score, class Agree: %.2f%%' % (f1_scores[3]*100))\n",
    "print(\"F1 score weighted: %.2f%%\" % (f1_score_weighted * 100.0))\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "list_of_models1.append(name)\n",
    "F1_score_unrelated1.append(f1_scores[0]*100)\n",
    "F1_score_disagree1.append(f1_scores[1]*100)\n",
    "F1_score_discuss1.append(f1_scores[2]*100)\n",
    "F1_score_agree1.append(f1_scores[3]*100)\n",
    "F1_score_weighted_list1.append(f1_score_weighted*100)\n",
    "accuracy_list1.append(accuracy*100)\n",
    "times1.append(time_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_dict1 = {'model' : list_of_models1, \n",
    "                'F1 score, class Unrelated' : F1_score_unrelated1, \n",
    "                'F1 score, class Disagree' : F1_score_disagree1, \n",
    "                'F1 score, class Discuss' : F1_score_discuss1, \n",
    "                'F1 score, class Agree' : F1_score_agree1, \n",
    "                'F1 score weighted' : F1_score_weighted_list1,\n",
    "                'Accuracy' : accuracy_list1, \n",
    "                'Time (in minutes)' : times1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_table1 = pd.DataFrame(summary_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score weighted</th>\n",
       "      <th>F1 score, class Agree</th>\n",
       "      <th>F1 score, class Disagree</th>\n",
       "      <th>F1 score, class Discuss</th>\n",
       "      <th>F1 score, class Unrelated</th>\n",
       "      <th>Time (in minutes)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.618109</td>\n",
       "      <td>82.495172</td>\n",
       "      <td>40.596628</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>66.475776</td>\n",
       "      <td>93.839085</td>\n",
       "      <td>10.29</td>\n",
       "      <td>Voting Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.961476</td>\n",
       "      <td>81.659915</td>\n",
       "      <td>44.274360</td>\n",
       "      <td>3.973510</td>\n",
       "      <td>63.608958</td>\n",
       "      <td>92.879688</td>\n",
       "      <td>0.30</td>\n",
       "      <td>Linear SVC (optimised)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.272341</td>\n",
       "      <td>82.170835</td>\n",
       "      <td>39.937679</td>\n",
       "      <td>12.321232</td>\n",
       "      <td>61.803809</td>\n",
       "      <td>94.159132</td>\n",
       "      <td>2.92</td>\n",
       "      <td>Decision Tree (optimised)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.102428</td>\n",
       "      <td>68.091496</td>\n",
       "      <td>26.500390</td>\n",
       "      <td>1.112656</td>\n",
       "      <td>34.780667</td>\n",
       "      <td>83.053165</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Extra Tree (optimised)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.932908</td>\n",
       "      <td>82.895680</td>\n",
       "      <td>43.390895</td>\n",
       "      <td>2.717391</td>\n",
       "      <td>66.800283</td>\n",
       "      <td>93.954142</td>\n",
       "      <td>6.55</td>\n",
       "      <td>Voting Classifier (optimised)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  F1 score weighted  F1 score, class Agree  \\\n",
       "0  84.618109          82.495172              40.596628   \n",
       "1  82.961476          81.659915              44.274360   \n",
       "2  83.272341          82.170835              39.937679   \n",
       "3  69.102428          68.091496              26.500390   \n",
       "4  84.932908          82.895680              43.390895   \n",
       "\n",
       "   F1 score, class Disagree  F1 score, class Discuss  \\\n",
       "0                  0.851064                66.475776   \n",
       "1                  3.973510                63.608958   \n",
       "2                 12.321232                61.803809   \n",
       "3                  1.112656                34.780667   \n",
       "4                  2.717391                66.800283   \n",
       "\n",
       "   F1 score, class Unrelated  Time (in minutes)                          model  \n",
       "0                  93.839085              10.29              Voting Classifier  \n",
       "1                  92.879688               0.30         Linear SVC (optimised)  \n",
       "2                  94.159132               2.92      Decision Tree (optimised)  \n",
       "3                  83.053165               0.10         Extra Tree (optimised)  \n",
       "4                  93.954142               6.55  Voting Classifier (optimised)  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It turns out that the best model in terms of accuracy and F1 score weighted is Logistic Regression set for multiclass classification with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "- improving classification of class disagree (below 1%)\n",
    "- improving classification of class agree (below 50%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
